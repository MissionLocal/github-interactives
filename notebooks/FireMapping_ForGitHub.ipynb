{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://data.sfgov.org/Public-Safety/Fire-Incidents/wr8u-xric\n",
    "df = pd.read_csv('https://data.sfgov.org/api/views/wr8u-xric/rows.csv?accessType=DOWNLOAD')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort out dates and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to datetime\n",
    "df['Alarm DtTm'] = pd.to_datetime(df['Alarm DtTm'])\n",
    "df['Arrival DtTm'] = pd.to_datetime(df['Arrival DtTm'])\n",
    "\n",
    "#same for incident date\n",
    "df['Incident Date'] = pd.to_datetime(df['Incident Date'])\n",
    "\n",
    "#figure out response times\n",
    "df['time_to_respond'] = df['Arrival DtTm'] - df['Alarm DtTm']\n",
    "df['time_to_respond'] = df['time_to_respond'].dt.total_seconds()\n",
    "\n",
    "#grab year\n",
    "df['incident_year'] = df['Incident Date'].astype(str).str[:4]\n",
    "#grab month\n",
    "df['incident_month'] = df['Incident Date'].astype(str).str[5:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapping fire incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract longs and lats from point column\n",
    "df['longitude'] = df['point'].str.extract(r'POINT \\((.*) ')\n",
    "df['latitude'] = df['point'].str.extract(r'(\\S*)\\)$')\n",
    "\n",
    "#convert longs and lats to float\n",
    "df['longitude'] = df['longitude'].astype(float)\n",
    "df['latitude'] = df['latitude'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### points map - 2021, fires, up-to-Oct, SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#just fires\n",
    "df1 = df[df['Primary Situation'].astype(str).str[0] == \"1\"]\n",
    "#just 2021\n",
    "df1_2021 = df1[df1['incident_year'] == \"2021\"]\n",
    "#excluding Nov\n",
    "df1_2021 = df1_2021[df1_2021['incident_month'] != \"11\"]\n",
    "\n",
    "#label each type of fire\n",
    "typeList = []\n",
    "for row in df1_2021['Primary Situation']:\n",
    "    if row[0:4] == \"1600\":\n",
    "        typeList.append(\"encampment\")\n",
    "    elif row[0:2] == \"15\":\n",
    "        typeList.append(\"trash\")\n",
    "    elif row[0:2] == \"13\":\n",
    "        typeList.append(\"vehicle\")\n",
    "    elif row[0:2] == \"11\":\n",
    "        typeList.append(\"structure\")\n",
    "    else:\n",
    "        typeList.append(\"other\")\n",
    "        \n",
    "df1_2021['type'] = typeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab just the most pertinent columns\n",
    "df1_2021Honed = df1_2021[['Incident Number','Address','Incident Date','time_to_respond','zipcode','Suppression Units','Suppression Personnel','Estimated Property Loss','Estimated Contents Loss','Primary Situation','Property Use','Area of Fire Origin','Ignition Cause','Ignition Factor Primary','neighborhood_district','type','latitude','longitude']]\n",
    "\n",
    "#remove number codes from situation descriptions\n",
    "df1_2021Honed['Primary Situation'] = df1_2021Honed['Primary Situation'].str.replace('^(\\d+ )', '')\n",
    "df1_2021Honed['Property Use'] = df1_2021Honed['Property Use'].str.replace('^(\\d+ )', '')\n",
    "\n",
    "#change column names\n",
    "df1_2021Honed.columns = ['id','address','date','time_to_respond','zipcode','suppression_units','suppression_personnel','est_property_loss','est_contents_loss','situation','property_use','fire_origin','ignition_cause','ignition_factor','neighborhood_district','type','latitude','longitude']\n",
    "\n",
    "#make date into string\n",
    "df1_2021Honed['date'] = df1_2021Honed['date'].astype(str)\n",
    "#get rid of year in date\n",
    "df1_2021Honed['date_string'] = pd.to_datetime(df1_2021Honed.date).dt.strftime('%d-%b-%Y').str[0:6]\n",
    "#get rid of hyphen in date\n",
    "df1_2021Honed['date_string'] = df1_2021Honed['date_string'].str.replace(\"-\",\" \")\n",
    "\n",
    "#make into geodataframe\n",
    "df1_2021Honed = gpd.GeoDataFrame(df1_2021Honed, geometry=gpd.points_from_xy(df1_2021Honed.longitude, df1_2021Honed.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort out minutes and seconds in response time\n",
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%2dm %2ds\" % (minutes, seconds)\n",
    "      \n",
    "stringTTR = []\n",
    "for row in df1_2021Honed['time_to_respond']:\n",
    "    stringTTR.append(convert(row).replace(\"  \", \" \"))\n",
    "    \n",
    "df1_2021Honed['time_to_respond_string'] = stringTTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as separate files\n",
    "df1_2021HonedTrash = df1_2021Honed[df1_2021Honed['type'] == \"trash\"]\n",
    "df1_2021HonedVehicle = df1_2021Honed[df1_2021Honed['type'] == \"vehicle\"]\n",
    "df1_2021HonedEncampment = df1_2021Honed[df1_2021Honed['type'] == \"encampment\"]\n",
    "df1_2021HonedStructure = df1_2021Honed[df1_2021Honed['type'] == \"structure\"]\n",
    "df1_2021HonedOther = df1_2021Honed[df1_2021Honed['type'] == \"other\"]\n",
    "\n",
    "df1_2021HonedTrash.to_file(\"fires2021_trash.geojson\", driver=\"GeoJSON\")\n",
    "df1_2021HonedVehicle.to_file(\"fires2021_vehicle.geojson\", driver=\"GeoJSON\")\n",
    "df1_2021HonedEncampment.to_file(\"fires2021_encampment.geojson\", driver=\"GeoJSON\")\n",
    "df1_2021HonedStructure.to_file(\"fires2021_structure.geojson\", driver=\"GeoJSON\")\n",
    "df1_2021HonedOther.to_file(\"fires2021_other.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change since 2015 by type, SF - STACKED BAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#between 2015 and end of Oct 2021\n",
    "df2 = df1[df1['Incident Date'].dt.date < datetime.date(2021,11,1)]\n",
    "df2 = df2[df2['Incident Date'].dt.date >= datetime.date(2015,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#label each type of fire and sort out order\n",
    "typeList = []\n",
    "for row in df2['Primary Situation']:\n",
    "    if row[0:4] == \"1600\":\n",
    "        typeList.append(\"encampment\")\n",
    "    elif row[0:2] == \"15\":\n",
    "        typeList.append(\"trash\")\n",
    "    elif row[0:2] == \"13\":\n",
    "        typeList.append(\"vehicle\")\n",
    "    elif row[0:2] == \"11\":\n",
    "        typeList.append(\"structure\")\n",
    "    else:\n",
    "        typeList.append(\"other\")\n",
    "df2['type'] = typeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just grab pertinent columns\n",
    "df2graph = df2.groupby(['incident_year','type']).count().reset_index()[['incident_year','type','Incident Number']]\n",
    "df2graph.columns = [['incident_year','type','value']]\n",
    "\n",
    "#save to csv and reload to remove weird string bug\n",
    "df2graph.to_csv('temp.csv')\n",
    "df2graph = pd.read_csv('temp.csv')\n",
    "\n",
    "#label each type of fire and sort out order\n",
    "orderList = []\n",
    "for row in df2graph['type']:\n",
    "    if row == \"trash\":\n",
    "        orderList.append(0)\n",
    "    elif row == \"encampment\":\n",
    "        orderList.append(1)\n",
    "    elif row == \"structure\":\n",
    "        orderList.append(2)\n",
    "    elif row == \"vehicle\":\n",
    "        orderList.append(3)\n",
    "    else:\n",
    "        orderList.append(4)\n",
    "df2graph['order'] = orderList\n",
    "\n",
    "#made incident year into a string\n",
    "df2graph['incident_year'] = df2graph['incident_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create bar chart\n",
    "alt.Chart(df2graph).mark_bar().encode(\n",
    "    x='incident_year',\n",
    "    y='value',\n",
    "    color='type',\n",
    "    order=alt.Order('order',sort='descending')\n",
    ").properties(width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just the mission - STACKED BAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = df2[df2['neighborhood_district'] == \"Mission\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just grab pertinent columns\n",
    "df3graph = df3.groupby(['incident_year','type']).count().reset_index()[['incident_year','type','Incident Number']]\n",
    "df3graph.columns = [['incident_year','type','value']]\n",
    "\n",
    "#save to csv and reload to remove weird string bug\n",
    "df3graph.to_csv('temp.csv')\n",
    "df3graph = pd.read_csv('temp.csv')\n",
    "\n",
    "#label each type of fire and sort out order\n",
    "orderList = []\n",
    "for row in df3graph['type']:\n",
    "    if row == \"trash\":\n",
    "        orderList.append(0)\n",
    "    elif row == \"encampment\":\n",
    "        orderList.append(1)\n",
    "    elif row == \"structure\":\n",
    "        orderList.append(2)\n",
    "    elif row == \"vehicle\":\n",
    "        orderList.append(3)\n",
    "    else:\n",
    "        orderList.append(4)\n",
    "df3graph['order'] = orderList\n",
    "\n",
    "#made incident year into a string\n",
    "df3graph['incident_year'] = df3graph['incident_year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bar chart\n",
    "alt.Chart(df3graph).mark_bar().encode(\n",
    "    x='incident_year',\n",
    "    y='value',\n",
    "    color='type',\n",
    "    order=alt.Order('order',sort='descending')\n",
    ").properties(width=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
